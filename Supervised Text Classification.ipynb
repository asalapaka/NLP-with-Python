{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simplified example of building a basic supervised text classification model.\n",
    "\n",
    "- **supervised**: we know the correct output class for each text in sample data\n",
    "- **text**: input data is in a text format\n",
    "- **classification model**: a model that uses input data to predict output class\n",
    "\n",
    "we will build a supervised sentiment classifier as we will be using a sentiment polarity data on movie reviews with a binary target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adarshsalapaka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/adarshsalapaka/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/adarshsalapaka/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import sample data and packages\n",
    "\n",
    "Firstly, let’s prepare the environment by importing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will transform movie_reviews tagged corpus from nltk to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for fileid in movie_reviews.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    reviews.append((tag, movie_reviews.raw(fileid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                           document\n",
       "0    neg  plot : two teen couples go to a church party ,...\n",
       "1    neg  the happy bastard's quick movie review \\ndamn ...\n",
       "2    neg  it is movies like these that make a jaded movi...\n",
       "3    neg   \" quest for camelot \" is warner bros . ' firs...\n",
       "4    neg  synopsis : a mentally unstable man undergoing ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.DataFrame(reviews, columns=['target', 'document'])\n",
    "print(f'Dimensions: {sample.shape}')\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that the dataframe has 2 columns: a column for the targets, the polarity sentiment, and a column for the reviews (i.e. documents) for 2000 reviews. Each review is either tagged as positive or negative review. Let’s check the counts of the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    1000\n",
       "neg    1000\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition data\n",
    "\n",
    "When it comes to partitioning data, we have 2 options:\n",
    "\n",
    " - Split the sample data into 3 groups: train, validation and test, where train is used to fit the model, validation is used to evaluate fitness of interim models, and test is used to assess final model fitness.\n",
    " - Split the sample data into 2 groups: train and test, where train is further split into train and validation set k times using k-fold cross validation, and test is used to assess final model fitness. With k-fold cross validation:\n",
    " \n",
    " \n",
    " - First: Train is split into k pieces.\n",
    " - Second: Take one piece for validation set to evaluate fitness of interim models after fitting the model to the remaining k-1 pieces.\n",
    " - Third: Repeat the second step k-1 times using a different piece for the validation set each time and the remaining for the train set such that each piece of train is used as validation set only once.\n",
    "\n",
    "\n",
    "Interim models here refer to the models created during the iterative process of comparing different machine learning classifiers as well as trying different hyperparameters for a given classifier to find the best model.\n",
    "\n",
    "We will be using the second option to partition the sample data. Let’s put aside some test data so that we could check how well the final model generalises on unseen data later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimensions: ((1400,), (1400,))\n",
      "Test dimensions: ((600,), (600,))\n",
      "pos    700\n",
      "neg    700\n",
      "Name: target, dtype: int64\n",
      "pos    300\n",
      "neg    300\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sample['document'], sample['target'], test_size=0.3, random_state=123)\n",
    "print(f'Train dimensions: {X_train.shape, y_train.shape}')\n",
    "print(f'Test dimensions: {X_test.shape, y_test.shape}')\n",
    "\n",
    "# Check out target distribution\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1400 documents in train and 600 documents in test dataset. The target is evenly distributed in both train and test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess documents\n",
    "\n",
    "It’s time to preprocess training documents, that is to transform unstructured data to a matrix of numbers. Let’s preprocess the text using an approach called bag-of-word where each text is represented by its words regardless of the order in which they are presented or the embedded grammar with the following steps:\n",
    "\n",
    "1. Tokenise\n",
    "2. Normalise\n",
    "3. Remove stop words\n",
    "4. Count vectorise\n",
    "5. Transform to tf-idf representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenise words while ignoring punctuation\n",
    "    tokeniser = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokeniser.tokenize(text)\n",
    "    \n",
    "    # Lowercase and lemmatise \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 27676)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of TfidfVectorizer\n",
    "vectoriser = TfidfVectorizer(analyzer=preprocess_text)\n",
    "\n",
    "# Fit to the data and transform to feature matrix\n",
    "X_train_tfidf = vectoriser.fit_transform(X_train)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we preprocess the text, our training data is now a 1400 x 27676 feature matrix stored in a sparse matrix format. This format provides an efficient storage of the data and speeds up subsequent processes. We have 27676 features that represent the unique words from the training dataset. Now, the training data is ready for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling\n",
    "\n",
    "Let’s build a baseline model using Stochastic Gradient Descent Classifier. I have chosen this classifier because it is fast and works well with sparse matrix. Using 5-fold cross validation, let’s fit the model to the data and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82857143 0.85       0.84285714 0.81785714 0.81428571]\n",
      "Accuracy: 0.83 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=123)\n",
    "sgf_clf_scores = cross_val_score(sgd_clf, X_train_tfidf, y_train, cv=5)\n",
    "\n",
    "print(sgf_clf_scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (sgf_clf_scores.mean(), sgf_clf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the data is perfectly balanced and we want both labels to be predicted as correctly as possible, we will use accuracy as a metric to evaluate the model fitness. \n",
    "\n",
    "However, accuracy is not always the best measure depending on the distribution of the target and relative misclassification costs of the classes. In which case, other evaluation metrics such as precision, recall or f1 may be more appropriate.\n",
    "\n",
    "The initial performance does not look bad. The baseline model can predict accurately ~83% +/- 3% of the time.\n",
    "Of note, the default metric used is accuracy in cross_val_score hence we don’t need to specify it unless you want to explicitly say so like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82857143, 0.85      , 0.84285714, 0.81785714, 0.81428571])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, X_train_tfidf, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s understand the predictions a bit further by looking at confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[580 120]\n",
      " [117 583]]\n"
     ]
    }
   ],
   "source": [
    "sgf_clf_pred = cross_val_predict(sgd_clf, X_train_tfidf, y_train, cv=5)\n",
    "\n",
    "print(confusion_matrix(y_train, sgf_clf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of predictions is similar for both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to improve performance\n",
    "\n",
    "The purpose of this section is to find the best machine learning algorithm as well as its hyperparameters. \n",
    "\n",
    "Let’s see if we are able to improve the model by tweaking some hyperparameters. We will leave most of the hyperparameters to its sensible default value. With the help of grid search, we will run a model with every combination o the hyperparameters specified below and cross validate the results to get a feel of its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': False,\n",
       " 'fit_intercept': False,\n",
       " 'loss': 'log',\n",
       " 'penalty': 'l1'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {'fit_intercept': [True,False],\n",
    "        'early_stopping': [True, False],\n",
    "        'loss' : ['hinge', 'log', 'squared_hinge'],\n",
    "        'penalty' : ['l2', 'l1', 'none']}\n",
    "\n",
    "search = GridSearchCV(estimator=sgd_clf, param_grid=grid, cv=5)\n",
    "search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the best values for the hyperparameters specified above. Let’s train and validate the model using these values for the selected hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85       0.85714286 0.83571429 0.84285714 0.82857143]\n",
      "Accuracy: 0.84 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "grid_sgd_clf_scores = cross_val_score(search.best_estimator_, X_train_tfidf, y_train, cv=5)\n",
    "print(grid_sgd_clf_scores)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (grid_sgd_clf_scores.mean(), grid_sgd_clf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model fitness is slightly better compared to initial model.\n",
    "\n",
    "We will choose these hyperparameter combiantion for our final model and stop this section here in the interest of time. However, this section could be extended further by trying different modelling techniques and finding optimal values for the hyperparameters of the model using a grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model\n",
    "\n",
    "Now that we have finalised the model, let’s put the data transformation step as well as the model in a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectoriser',\n",
       "                 TfidfVectorizer(analyzer=<function preprocess_text at 0x7f7f9c640050>)),\n",
       "                ('classifier',\n",
       "                 SGDClassifier(fit_intercept=False, loss='log', penalty='l1',\n",
       "                               random_state=123))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('vectoriser', vectoriser),\n",
    "                 ('classifier', search.best_estimator_)])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code shown above, the pipeline first transforms the unstructured data to a feature matrix, then fits the preprocessed data to the model. This is an elegant way of putting together the essential steps in a single pipeline.\n",
    "\n",
    "Let’s assess the predictive power of the model on the test set. Here, we will pass the test data to the pipeline, which will first preprocess the data then make predictions using the previously fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "[[249  51]\n",
      " [ 37 263]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy: %0.2f\" % (accuracy_score(y_test, y_test_pred)))\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the final model on unseen data is ~85%. If this test data is representative of future data, the predictive power of the model is decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
